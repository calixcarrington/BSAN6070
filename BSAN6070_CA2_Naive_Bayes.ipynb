{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BSAN6070-CA2-Naive Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrK_r0qqJdBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "#importing all required libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF26KydOLSLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the dictionary with 3000 most common words\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "#initiate dictionary with empty list so common words can fill in.\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "#the for loop starts with opening the mails from emails then splitting each word per line.\n",
        "#words are then added into the list of all_words and then use the counter function to keep count of the mail content.\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "#remove non-alphanumeric symbols in dictionary\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "#also removes single alphanumeric characters\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "#limits to 3000 most common words\n",
        "  return dictionary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNe-5pRVPGZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setting up the matrix, extract the feature columns and populating them with values\n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "#to initiate a matrix and set all the numbers as 0\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "#starts reading from third line because content of email starts there\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "#this creates and counts the numbers of words and puts them in a matrix of docID,wordID\n",
        "#the words that are counted are those included in the dictionary of 3000 common words\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "#tracks the files and their paths by splitting per path\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "#if loop to go through the emails and identify spam type emails through those starting with 'spmsg'\n",
        "  return features_matrix, train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH19WkdrXrdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9126b417-f263-4e33-9b22-6fa244a09a91"
      },
      "source": [
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/test-mails'\n",
        "#setting the train and test sets\n",
        "\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "#sets the dictionary with the words in TRAIN_DIR\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "#extracts the features again using the train and test models\n",
        "\n",
        "model = GaussianNB()\n",
        "#set the Naive Bayes model training method\n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels)\n",
        "#used for training the dataset\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "#test the spam messages\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))\n",
        "#scores the test data set after running against the train and test sets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}